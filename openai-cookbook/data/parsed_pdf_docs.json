[{"filename": "rag-deck.pdf", "text": "RAG\nTechnique\n\nFebruary 2024\n\n\fOverview\n\nRetrieval-Augmented Generation \nenhances the capabilities of language \nmodels by combining them with a \nretrieval system. This allows the model \nto leverage external knowledge sources \nto generate more accurate and \ncontextually relevant responses.\n\nExample use cases\n\n- Provide answers with up-to-date \n\ninformation\n\n- Generate contextual responses\n\nWhat we\u2019ll cover\n\n\u25cf Technical patterns\n\n\u25cf Best practices\n\n\u25cf Common pitfalls\n\n\u25cf Resources\n\n3\n\n\fWhat is RAG\n\nRetrieve information to Augment the model\u2019s knowledge and Generate the output\n\n\u201cWhat is your \nreturn policy?\u201d\n\nask\n\nresult\n\nsearch\n\nLLM\n\nreturn information\n\nTotal refunds: 0-14 days\n50% of value vouchers: 14-30 days\n$5 discount on next order: > 30 days\n\n\u201cYou can get a full refund up \nto 14 days after the \npurchase, then up to 30 days \nyou would get a voucher for \nhalf the value of your order\u201d\n\nKnowledge \nBase / External \nsources\n\n4\n\n\fWhen to use RAG\n\nGood for  \u2705\n\nNot good for  \u274c\n\n\u25cf\n\n\u25cf\n\nIntroducing new information to the model \n\n\u25cf\n\nTeaching the model a speci\ufb01c format, style, \n\nto update its knowledge\n\nReducing hallucinations by controlling \n\ncontent\n\n/!\\ Hallucinations can still happen with RAG\n\nor language\n\u2794 Use \ufb01ne-tuning or custom models instead\n\n\u25cf\n\nReducing token usage\n\u2794 Consider \ufb01ne-tuning depending on the use \n\ncase\n\n5\n\n\fTechnical patterns\n\nData preparation\n\nInput processing\n\nRetrieval\n\nAnswer Generation\n\n\u25cf Chunking\n\n\u25cf\n\n\u25cf\n\nEmbeddings\n\nAugmenting \ncontent\n\n\u25cf\n\nInput \naugmentation\n\n\u25cf NER\n\n\u25cf\n\nSearch\n\n\u25cf Context window\n\n\u25cf Multi-step \nretrieval\n\n\u25cf Optimisation\n\n\u25cf\n\nSafety checks\n\n\u25cf\n\nEmbeddings\n\n\u25cf Re-ranking\n\n6\n\n\fTechnical patterns\nData preparation\n\nchunk documents into multiple \npieces for easier consumption\n\ncontent\n\nembeddings\n\n0.983, 0.123, 0.289\u2026\n\n0.876, 0.145, 0.179\u2026\n\n0.983, 0.123, 0.289\u2026\n\nAugment content \nusing LLMs\n\nEx: parse text only, ask gpt-4 to rephrase & \nsummarize each part, generate bullet points\u2026\n\nBEST PRACTICES\n\nPre-process content for LLM \nconsumption: \nAdd summary, headers for each \npart, etc.\n+ curate relevant data sources\n\nKnowledge \nBase\n\nCOMMON PITFALLS\n\n\u2794 Having too much low-quality \n\ncontent\n\n\u2794 Having too large documents\n\n7\n\n\fTechnical patterns\nData preparation: chunking\n\nWhy chunking?\n\nIf your system doesn\u2019t require \nentire documents to provide \nrelevant answers, you can \nchunk them into multiple pieces \nfor easier consumption (reduced \ncost & latency).\n\nOther approaches: graphs or \nmap-reduce\n\nThings to consider\n\n\u25cf\n\nOverlap:\n\n\u25cb\n\n\u25cb\n\nShould chunks be independent or overlap one \nanother?\nIf they overlap, by how much?\n\n\u25cf\n\nSize of chunks: \n\n\u25cb What is the optimal chunk size for my use case?\n\u25cb\n\nDo I want to include a lot in the context window or \njust the minimum?\n\n\u25cf Where to chunk:\n\n\u25cb\n\n\u25cb\n\nShould I chunk every N tokens or use speci\ufb01c \nseparators? \nIs there a logical way to split the context that would \nhelp the retrieval process?\n\n\u25cf What to return:\n\n\u25cb\n\n\u25cb\n\nShould I return chunks across multiple documents \nor top chunks within the same doc?\nShould chunks be linked together with metadata to \nindicate common properties?\n\n8\n\n\fTechnical patterns\nData preparation: embeddings\n\nWhat to embed?\n\nDepending on your use case \nyou might not want just to \nembed the text in the \ndocuments but metadata as well \n- anything that will make it easier \nto surface this speci\ufb01c chunk or \ndocument when performing a \nsearch\n\nExamples\n\nEmbedding Q&A posts in a forum\nYou might want to embed the title of the posts, \nthe text of the original question and the content of \nthe top answers.\nAdditionally, if the posts are tagged by topic or \nwith keywords, you can embed those too.\n\nEmbedding product specs\nIn additional to embedding the text contained in \ndocuments describing the products, you might \nwant to add metadata that you have on the \nproduct such as the color, size, etc. in your \nembeddings.\n\n9\n\n\fTechnical patterns\nData preparation: augmenting content\n\nWhat does \u201cAugmenting \ncontent\u201d mean?\n\nAugmenting content refers to \nmodi\ufb01cations of the original content \nto make it more digestible for a \nsystem relying on RAG. The \nmodi\ufb01cations could be a change in \nformat, wording, or adding \ndescriptive content such as \nsummaries or keywords.\n\nExample approaches\n\nMake it a guide*\nReformat the content to look more like \na step-by-step guide with clear \nheadings and bullet-points, as this \nformat is more easily understandable \nby an LLM.\n\nAdd descriptive metadata*\nConsider adding keywords or text that \nusers might search for when thinking \nof a speci\ufb01c product or service.\n\nMultimodality\nLeverage models \nsuch as Whisper or \nGPT-4V to \ntransform audio or \nvisual content into \ntext.\nFor example, you \ncan use GPT-4V to \ngenerate tags for \nimages or to \ndescribe slides.\n\n* GPT-4 can do this for you with the right prompt\n\n10\n\n\fTechnical patterns\nInput processing\n\nProcess input according to task\n\nQ&A\nHyDE:  Ask LLM to hypothetically answer the \nquestion & use the answer to search the KB\n\nembeddings\n\n0.983, 0.123, 0.289\u2026\n\n0.876, 0.145, 0.179\u2026\n\nContent search\nPrompt LLM to rephrase input & optionally add \nmore context\n\nquery\n\nSELECT * from items\u2026\n\nDB search\nNER:  Find relevant entities to be used for a \nkeyword search or to construct a search query\n\nkeywords\n\nred\n\nsummer\n\nBEST PRACTICES\n\nConsider how to transform the \ninput to match content in the \ndatabase\nConsider using metadata to \naugment the user input\n\nCOMMON PITFALLS\n\n\u2794 Comparing directly the input \nto the database without \nconsidering the task \nspeci\ufb01cities \n\n11\n\n\fTechnical patterns\nInput processing: input augmentation\n\nWhat is input augmentation?\n\nExample approaches\n\nAugmenting the input means turning \nit into something di\ufb00erent, either \nrephrasing it, splitting it in several \ninputs or expanding it.\nThis helps boost performance as \nthe LLM might understand better \nthe user intent.\n\nQuery \nexpansion*\nRephrase the \nquery to be \nmore \ndescriptive\n\nHyDE*\nHypothetically \nanswer the \nquestion & use \nthe answer to \nsearch the KB\n\nSplitting a query in N*\nWhen there is more than 1 question or \nintent in a user query, consider \nsplitting it in several queries\n\nFallback\nConsider \nimplementing a \n\ufb02ow where the LLM \ncan ask for \nclari\ufb01cation when \nthere is not enough \ninformation in the \noriginal user query \nto get a result\n(Especially relevant \nwith tool usage)\n\n* GPT-4 can do this for you with the right prompt\n\n12\n\n\fTechnical patterns\nInput processing: NER\n\nWhy use NER?\n\nUsing NER (Named Entity \nRecognition) allows to extract \nrelevant entities from the input, that \ncan then be used for more \ndeterministic search queries. \nThis can be useful when the scope \nis very constrained.\n\nExample\n\nSearching for movies\nIf you have a structured database containing \nmetadata on movies, you can extract genre, \nactors or directors names, etc. from the user \nquery and use this to search the database\n\nNote: You can use exact values or embeddings after \nhaving extracted the relevant entities\n\n13\n\n\fTechnical patterns\nRetrieval\n\nre-ranking\n\nINPUT\n\nembeddings\n\n0.983, 0.123, 0.289\u2026\n\n0.876, 0.145, 0.179\u2026\n\nquery\n\nSELECT * from items\u2026\n\nkeywords\n\nred\n\nsummer\n\nSemantic \nsearch\n\nRESULTS\n\nRESULTS\n\nvector DB\n\nrelational / \nnosql db\n\nFINAL RESULT\n\nUsed to \ngenerate output\n\nBEST PRACTICES\n\nUse a combination of semantic \nsearch and deterministic queries \nwhere possible\n\n+ Cache output where possible\n\nCOMMON PITFALLS\n\n\u2794 The wrong elements could be \ncompared when looking at \ntext similarity, that is why \nre-ranking is important\n\n14\n\n\fTechnical patterns\nRetrieval: search\n\nHow to search?\n\nSemantic search\n\nKeyword search\n\nSearch query\n\nThere are many di\ufb00erent \napproaches to search depending on \nthe use case and the existing \nsystem.\n\nUsing embeddings, you \ncan perform semantic \nsearches. You can \ncompare embeddings \nwith what is in your \ndatabase and \ufb01nd the \nmost similar.\n\nIf you have extracted \nspeci\ufb01c entities or \nkeywords to search for, \nyou can search for these \nin your database.\n\nBased on the extracted \nentities you have or the \nuser input as is, you can \nconstruct search queries \n(SQL, cypher\u2026) and use \nthese queries to search \nyour database.\n\nYou can use a hybrid approach and combine several of these.\nYou can perform multiple searches in parallel or in sequence, or \nsearch for keywords with their embeddings for example.\n\n15\n\n\fTechnical patterns\nRetrieval: multi-step retrieval\n\nWhat is multi-step retrieval?\n\nIn some cases, there might be \nseveral actions to be performed to \nget the required information to \ngenerate an answer.\n\nThings to consider\n\n\u25cf\n\nFramework to be used:\n\n\u25cb When there are multiple steps to perform, \nconsider whether you want to handle this \nyourself or use a framework to make it easier\n\n\u25cf\n\nCost & Latency:\n\n\u25cb\n\n\u25cb\n\nPerforming multiple steps at the retrieval \nstage can increase latency and cost \nsigni\ufb01cantly\nConsider performing actions in parallel to \nreduce latency\n\n\u25cf\n\nChain of Thought:\n\n\u25cb\n\n\u25cb\n\nGuide the assistant with the chain of thought \napproach: break down instructions into \nseveral steps, with clear guidelines on \nwhether to continue, stop or do something \nelse. \nThis is more appropriate when tasks need to \nbe performed sequentially - for example: \u201cif \nthis didn\u2019t work, then do this\u201d\n\n16\n\n\fTechnical patterns\nRetrieval: re-ranking\n\nWhat is re-ranking?\n\nExample approaches\n\nRe-ranking means re-ordering the \nresults of the retrieval process to \nsurface more relevant results.\nThis is particularly important when \ndoing semantic searches.\n\nRule-based re-ranking\nYou can use metadata to rank results by relevance. For \nexample, you can look at the recency of the documents, at \ntags, speci\ufb01c keywords in the title, etc.\n\nRe-ranking algorithms\nThere are several existing algorithms/approaches you can use \nbased on your use case: BERT-based re-rankers, \ncross-encoder re-ranking, TF-IDF algorithms\u2026\n\n17\n\n\fTechnical patterns\nAnswer Generation\n\nFINAL RESULT\n\nPiece of content \nretrieved\n\nLLM\n\nPrompt including \nthe content\n\nUser sees the \n\ufb01nal result\n\nBEST PRACTICES\n\nEvaluate performance after each \nexperimentation to assess if it\u2019s \nworth exploring other paths\n+ Implement guardrails if applicable\n\nCOMMON PITFALLS\n\n\u2794 Going for \ufb01ne-tuning without \ntrying other approaches\n\u2794 Not paying attention to the \nway the model is prompted\n\n18\n\n\fTechnical patterns\nAnswer Generation: context window\n\nHow to manage context?\n\nDepending on your use case, there are \nseveral things to consider when \nincluding retrieved content into the \ncontext window to generate an answer. \n\nThings to consider\n\n\u25cf\n\nContext window max size:\n\n\u25cb\n\n\u25cb\n\nThere is a maximum size, so putting too \nmuch content is not ideal\nIn conversation use cases, the \nconversation will be part of the context \nas well and will add to that size\n\n\u25cf\n\nCost & Latency vs Accuracy:\n\n\u25cb More context results in increased \n\nlatency and additional costs since there \nwill be more input tokens\nLess context might also result in \ndecreased accuracy\n\n\u25cb\n\n\u25cf\n\n\u201cLost in the middle\u201d problem:\n\n\u25cb When there is too much context, LLMs \ntend to forget the text \u201cin the middle\u201d of \nthe content and might look over some \nimportant information.\n\n19\n\n\fTechnical patterns\nAnswer Generation: optimisation\n\nHow to optimise?\n\nThere are a few di\ufb00erent \nmethods to consider when \noptimising a RAG application.\nTry them from left to right, and \niterate with several of these \napproaches if needed.\n\nPrompt Engineering\n\nFew-shot examples\n\nFine-tuning\n\nAt each point of the \nprocess, experiment with \ndi\ufb00erent prompts to get \nthe expected input format \nor generate a relevant \noutput.\nTry guiding the model if \nthe process to get to the \n\ufb01nal outcome contains \nseveral steps.\n\nIf the model doesn\u2019t \nbehave as expected, \nprovide examples of what \nyou want e.g. provide \nexample user inputs and \nthe expected processing \nformat.\n\nIf giving a few examples \nisn\u2019t enough, consider \n\ufb01ne-tuning a model with \nmore examples for each \nstep of the process: you \ncan \ufb01ne-tune to get a \nspeci\ufb01c input processing \nor output format.\n\n20\n\n\fTechnical patterns\nAnswer Generation: safety checks\n\nWhy include safety checks?\n\nJust because you provide the model \nwith (supposedly) relevant context \ndoesn\u2019t mean the answer will \nsystematically be truthful or on-point.\nDepending on the use case, you \nmight want to double-check. \n\nExample evaluation framework: RAGAS\n\n21\n\n\f", "pages_description": ["**Overview**\n\nRetrieval-Augmented Generation (RAG) enhances language models by integrating them with a retrieval system. This combination allows the model to access external knowledge sources, resulting in more accurate and contextually relevant responses. \n\n**Example Use Cases:**\n- Providing answers with up-to-date information.\n- Generating contextual responses.\n\n**What We\u2019ll Cover:**\n- Technical patterns\n- Best practices\n- Common pitfalls\n- Resources", "What is RAG\n\nRAG stands for \"Retrieve information to Augment the model\u2019s knowledge and Generate the output.\" It is a process that involves using a language model (LLM) to enhance its responses by retrieving relevant information from external sources or a knowledge base.\n\nHere's how it works:\n\n1. **User Query**: A user asks a question, such as \"What is your return policy?\"\n\n2. **LLM Processing**: The language model receives the query and initiates a search for relevant information.\n\n3. **Information Retrieval**: The LLM accesses a knowledge base or external sources to find the necessary details. In this example, the knowledge base contains information about the return policy, such as:\n   - Total refunds available from 0 to 14 days.\n   - 50% value vouchers for returns between 14 to 30 days.\n   - A $5 discount on the next order for returns after 30 days.\n\n4. **Response Generation**: The LLM uses the retrieved information to generate a coherent response. For instance, it might say, \"You can get a full refund up to 14 days after the purchase, then up to 30 days you would get a voucher for half the value of your order.\"\n\nThis process allows the model to provide accurate and contextually relevant answers by leveraging external data sources.", "**When to use RAG**\n\n**Good for:**\n\n- **Introducing new information to the model:** RAG (Retrieval-Augmented Generation) is effective for updating a model's knowledge by incorporating new data.\n\n- **Reducing hallucinations by controlling content:** While RAG can help minimize hallucinations, it's important to note that they can still occur.\n\n**Not good for:**\n\n- **Teaching the model a specific format, style, or language:** For these tasks, it's better to use fine-tuning or custom models.\n\n- **Reducing token usage:** If token usage is a concern, consider fine-tuning based on the specific use case.", "**Technical Patterns**\n\nThis image outlines four key technical patterns involved in data processing and answer generation:\n\n1. **Data Preparation**\n   - **Chunking**: Breaking down data into smaller, manageable pieces.\n   - **Embeddings**: Converting data into numerical formats that can be easily processed by machine learning models.\n   - **Augmenting Content**: Enhancing data with additional information to improve its quality or usefulness.\n\n2. **Input Processing**\n   - **Input Augmentation**: Modifying or enriching input data to improve model performance.\n   - **NER (Named Entity Recognition)**: Identifying and classifying key entities within the data.\n   - **Embeddings**: Similar to data preparation, embeddings are used to represent input data in a format suitable for processing.\n\n3. **Retrieval**\n   - **Search**: Locating relevant information from a dataset.\n   - **Multi-step Retrieval**: Using multiple steps or methods to refine search results.\n   - **Re-ranking**: Adjusting the order of retrieved results to prioritize the most relevant information.\n\n4. **Answer Generation**\n   - **Context Window**: Using a specific portion of data to generate relevant answers.\n   - **Optimisation**: Improving the efficiency and accuracy of the answer generation process.\n   - **Safety Checks**: Ensuring that generated answers are safe and appropriate for use.", "Technical Patterns: Data Preparation\n\nThis guide focuses on preparing data for easier consumption by large language models (LLMs). The process involves several key steps and considerations:\n\n1. **Chunking Documents**: \n   - Break down large documents into smaller, manageable pieces. This makes it easier for models to process and understand the content.\n\n2. **Embeddings**:\n   - Each chunk of content is converted into embeddings, which are numerical representations of the text. These embeddings are then stored in a knowledge base for efficient retrieval and use.\n\n3. **Augmenting Content**:\n   - Use LLMs to enhance the content. For example, you can parse text, rephrase and summarize each part, and generate bullet points to improve clarity and accessibility.\n\n4. **Best Practices**:\n   - Pre-process content specifically for LLM consumption by adding summaries and headers for each section.\n   - Curate relevant data sources to ensure the quality and relevance of the information.\n\n5. **Common Pitfalls**:\n   - Avoid having too much low-quality content, as it can degrade the performance of the model.\n   - Be cautious of using overly large documents, which can be difficult for models to handle effectively.\n\nBy following these guidelines, you can optimize data preparation for better performance and outcomes with LLMs.", "**Technical Patterns: Data Preparation - Chunking**\n\n**Why Chunking?**\n\nChunking is a technique used when your system doesn't need entire documents to provide relevant answers. By breaking documents into smaller pieces, you can make data easier to process, which reduces cost and latency. This approach is beneficial for systems that need to handle large volumes of data efficiently. Other methods for data preparation include using graphs or map-reduce.\n\n**Things to Consider**\n\n1. **Overlap:**\n   - Decide whether chunks should be independent or overlap with each other.\n   - If overlap is necessary, determine the extent of the overlap.\n\n2. **Size of Chunks:**\n   - Identify the optimal chunk size for your specific use case.\n   - Consider whether to include a lot of information in the context window or just the minimum required.\n\n3. **Where to Chunk:**\n   - Determine if you should chunk every N tokens or use specific separators.\n   - Look for logical ways to split the context that would aid the retrieval process.\n\n4. **What to Return:**\n   - Decide if you should return chunks from multiple documents or focus on top chunks within the same document.\n   - Consider linking chunks with metadata to indicate common properties. \n\nThese considerations help in optimizing the chunking process to suit the needs of your system, ensuring efficient data handling and retrieval.", "Technical Patterns: Data Preparation - Embeddings\n\n**What to Embed?**\n\nWhen preparing data for embedding, it's important to consider not just the text but also the metadata. This approach can enhance the searchability and relevance of the data. Metadata includes any additional information that can help identify or categorize the document, making it easier to retrieve specific chunks during a search.\n\n**Examples:**\n\n1. **Embedding Q&A Posts in a Forum:**\n   - You might embed the title of the posts, the text of the original question, and the content of the top answers.\n   - If the posts are tagged by topic or with keywords, these can also be embedded to improve searchability.\n\n2. **Embedding Product Specs:**\n   - Beyond embedding the text from product descriptions, you can include metadata such as color, size, and other specifications.\n   - This additional information can be crucial for creating more detailed and useful embeddings.", "Technical Patterns: Data Preparation - Augmenting Content\n\n**What does \u201cAugmenting content\u201d mean?**\n\nAugmenting content involves modifying the original content to make it more digestible for systems that rely on Retrieval-Augmented Generation (RAG). These modifications can include changes in format, wording, or the addition of descriptive content like summaries or keywords.\n\n**Example Approaches**\n\n1. **Make it a Guide**\n   - Reformat the content to resemble a step-by-step guide with clear headings and bullet points. This format is more easily understandable by a Large Language Model (LLM). For instance, GPT-4 can assist in this transformation with the right prompt.\n\n2. **Add Descriptive Metadata**\n   - Incorporate keywords or text that users might search for when considering a specific product or service. This helps in making the content more accessible and searchable.\n\n3. **Multimodality**\n   - Utilize models such as Whisper or GPT-4V to convert audio or visual content into text. For example, GPT-4V can generate tags for images or describe slides, enhancing the content's accessibility and usability.", "Technical Patterns: Input Processing\n\n**Process Input According to Task**\n\n1. **Q&A**: \n   - Use HyDE to ask a Language Learning Model (LLM) to hypothetically answer a question. This answer is then used to search the Knowledge Base (KB).\n\n2. **Content Search**: \n   - Prompt the LLM to rephrase the input and optionally add more context to enhance the search process.\n\n3. **DB Search**: \n   - Utilize Named Entity Recognition (NER) to find relevant entities. These entities can be used for keyword searches or to construct a search query.\n\n**Output Methods**\n\n- **Embeddings**: \n  - Numerical representations of input, such as vectors (e.g., 0.983, 0.123, 0.289).\n\n- **Query**: \n  - Structured database queries (e.g., SELECT * from items).\n\n- **Keywords**: \n  - Specific terms extracted from the input (e.g., \"red,\" \"summer\").\n\n**Best Practices**\n\n- Transform the input to match the content in the database effectively.\n- Use metadata to augment user input, enhancing the search and retrieval process.\n\n**Common Pitfalls**\n\n- Avoid directly comparing the input to the database without considering the specificities of the task, as this can lead to inaccurate results.", "**Technical Patterns: Input Processing - Input Augmentation**\n\n**What is input augmentation?**\n\nInput augmentation involves transforming the input into something different by rephrasing, splitting it into several parts, or expanding it. This process enhances the performance of language models (LLMs) by helping them better understand user intent.\n\n**Example Approaches:**\n\n1. **Query Expansion**\n   - Rephrase the query to make it more descriptive. This helps the LLM grasp the context and details more effectively.\n\n2. **HyDE**\n   - Hypothetically answer the question and use that answer to search the knowledge base (KB). This approach can provide more context and improve the accuracy of the response.\n\n3. **Splitting a Query in N**\n   - When a user query contains multiple questions or intents, consider splitting it into several queries. This allows each part to be addressed more thoroughly.\n\n4. **Fallback**\n   - Implement a flow where the LLM can ask for clarification if the original query lacks sufficient information. This is particularly useful when using tools that require precise input.\n\n*Note: GPT-4 can perform these tasks with the right prompt.*", "Technical Patterns: Input Processing - NER\n\n**Why use NER?**\n\nNamed Entity Recognition (NER) is a technique used to extract relevant entities from input data. This process allows for more deterministic search queries, which is particularly useful when the scope is very constrained. By identifying specific entities, such as names, dates, or locations, NER helps in refining and improving the accuracy of searches.\n\n**Example: Searching for Movies**\n\nImagine you have a structured database containing metadata on movies. By using NER, you can extract specific entities like genre, actors, or directors' names from a user's query. This information can then be used to search the database more effectively.\n\n**Note:** After extracting the relevant entities, you can use exact values or embeddings to enhance the search process.", "**Technical Patterns: Retrieval**\n\nThis diagram illustrates a retrieval process using technical patterns. Here's a breakdown of the components and flow:\n\n1. **Input:**\n   - **Embeddings:** These are numerical representations of data, shown as vectors (e.g., 0.983, 0.123, 0.289). They are used for semantic search in a vector database (DB).\n   - **Query:** A structured query (e.g., \"SELECT * from items...\") is used to retrieve data from a relational or NoSQL database.\n   - **Keywords:** Simple search terms (e.g., \"red,\" \"summer\") are also used in the relational or NoSQL database.\n\n2. **Process:**\n   - **Semantic Search:** Embeddings are processed through a vector DB to find semantically similar results.\n   - **Re-ranking:** Initial results from the vector DB are re-ranked to improve accuracy and relevance.\n   - **Final Result:** The re-ranked results are combined with those from the relational/NoSQL DB to generate the final output.\n\n3. **Best Practices:**\n   - Use a combination of semantic search and deterministic queries to enhance retrieval accuracy.\n   - Cache outputs where possible to improve efficiency.\n\n4. **Common Pitfalls:**\n   - Incorrect element comparison during text similarity checks can occur, highlighting the importance of re-ranking to ensure relevant results.\n\nThis approach leverages both semantic and traditional search methods to optimize data retrieval, ensuring more accurate and relevant results.", "Technical Patterns: Retrieval - Search\n\n**How to search?**\n\nThere are various approaches to searching, which depend on the specific use case and the existing system. Here are three primary methods:\n\n1. **Semantic Search**:\n   - This method uses embeddings to perform searches. \n   - By comparing embeddings with the data in your database, you can find the most similar matches.\n\n2. **Keyword Search**:\n   - If you have specific entities or keywords extracted, you can search for these directly in your database.\n\n3. **Search Query**:\n   - Based on extracted entities or direct user input, you can construct search queries (such as SQL or Cypher) to search your database.\n\nAdditionally, you can use a hybrid approach by combining several methods. This can involve performing multiple searches in parallel or in sequence, or searching for keywords using their embeddings, for example.", "Technical Patterns: Retrieval - Multi-step Retrieval\n\n**What is multi-step retrieval?**\n\nMulti-step retrieval involves performing several actions to obtain the necessary information to generate an answer. This approach is useful when a single step is insufficient to gather all required data.\n\n**Things to Consider**\n\n1. **Framework to be Used:**\n   - When multiple steps are needed, decide whether to manage this process yourself or use a framework to simplify it.\n\n2. **Cost & Latency:**\n   - Performing multiple steps can significantly increase both latency and cost.\n   - To mitigate this, consider executing actions in parallel to reduce latency.\n\n3. **Chain of Thought:**\n   - Guide the process using a chain of thought approach. Break down instructions into several steps with clear guidelines on whether to continue, stop, or take alternative actions.\n   - This method is particularly useful for tasks that need to be performed sequentially, such as \"if this didn\u2019t work, then do this.\"", "**Technical Patterns: Retrieval - Re-ranking**\n\n**What is re-ranking?**\n\nRe-ranking involves re-ordering the results obtained from a retrieval process to highlight more relevant outcomes. This is especially crucial in semantic searches, where understanding the context and meaning of the search query is important.\n\n**Example Approaches**\n\n1. **Rule-based Re-ranking**\n   - This approach uses metadata to rank results by relevance. For instance, you can consider the recency of documents, tags, or specific keywords in the title to determine their importance.\n\n2. **Re-ranking Algorithms**\n   - There are various algorithms available for re-ranking based on specific use cases. Examples include:\n     - BERT-based re-rankers\n     - Cross-encoder re-ranking\n     - TF-IDF algorithms\n\nThese methods help in refining search results to better meet the user's needs by considering different aspects of the data.", "Technical Patterns: Answer Generation\n\nThis diagram illustrates the process of answer generation using a language model (LLM). Here's a breakdown of the components and concepts:\n\n1. **Process Flow**:\n   - A piece of content is retrieved and used to form a prompt.\n   - This prompt is fed into the LLM, which processes it to generate a final result.\n   - The user then sees this final result.\n\n2. **Best Practices**:\n   - **Evaluate Performance**: After each experiment, assess the performance to determine if exploring other methods is beneficial.\n   - **Implement Guardrails**: If applicable, add safeguards to ensure the model's outputs are reliable and appropriate.\n\n3. **Common Pitfalls**:\n   - **Premature Fine-Tuning**: Avoid jumping straight to fine-tuning the model without trying other approaches first.\n   - **Prompting Attention**: Ensure careful attention is given to how the model is prompted, as this can significantly affect the output quality.\n\nThis framework emphasizes the importance of iterative evaluation and careful prompting to optimize the performance of language models in generating answers.", "Technical Patterns: Answer Generation - Context Window\n\nHow to manage context?\n\nWhen generating answers using a context window, it's important to consider several factors based on your specific use case. Here are key points to keep in mind:\n\n1. **Context Window Max Size**:\n   - The context window has a maximum size, so overloading it with too much content is not advisable.\n   - In conversational scenarios, the ongoing conversation itself becomes part of the context, contributing to the overall size.\n\n2. **Cost & Latency vs. Accuracy**:\n   - Including more context can lead to increased latency and higher costs due to the greater number of input tokens.\n   - Conversely, providing less context might reduce accuracy.\n\n3. **\"Lost in the Middle\" Problem**:\n   - When the context is too extensive, language models may overlook or forget information that appears in the middle of the content, potentially missing important details.\n\nThese considerations are crucial for effectively managing context to generate accurate and efficient answers.", "Technical Patterns: Answer Generation Optimisation\n\nWhen optimizing a Retrieval-Augmented Generation (RAG) application, there are several methods to consider. These methods can be tried sequentially and iteratively to achieve the best results.\n\n1. **Prompt Engineering**:\n   - Experiment with different prompts at each stage of the process to achieve the desired input format or generate relevant outputs.\n   - Guide the model through multiple steps to reach the final outcome.\n\n2. **Few-shot Examples**:\n   - If the model's behavior is not as expected, provide examples of the desired outcome.\n   - Use example user inputs and the expected processing format to guide the model.\n\n3. **Fine-tuning**:\n   - If a few examples are insufficient, consider fine-tuning the model with more examples for each process step.\n   - Fine-tuning can help achieve specific input processing or output formats. \n\nThese strategies can be combined and adjusted as needed to optimize the performance of a RAG application.", "Technical Patterns: Answer Generation - Safety Checks\n\n**Why include safety checks?**\n\nSafety checks are crucial in answer generation because providing a model with supposedly relevant context does not guarantee that the answer will be truthful or accurate. Depending on the use case, it is important to double-check the generated answers to ensure reliability.\n\n**RAGAS Score Evaluation Framework**\n\nThe RAGAS score is an evaluation framework that assesses both the generation and retrieval aspects of answer generation:\n\n- **Generation:**\n  - **Faithfulness:** This measures how factually accurate the generated answer is.\n  - **Answer Relevancy:** This evaluates how relevant the generated answer is to the question.\n\n- **Retrieval:**\n  - **Context Precision:** This assesses the signal-to-noise ratio of the retrieved context, ensuring that the context is precise and relevant.\n  - **Context Recall:** This checks if all the relevant information required to answer the question is retrieved effectively.\n\nIncorporating these safety checks and evaluation metrics helps in producing more reliable and accurate answers."]}, {"filename": "models-page.pdf", "text": "26/02/2024, 17:58\n\nModels - OpenAI API\n\nDocumentation\n\nAPI reference\n\nForum \n\nHelp \n\nModels\n\nOverview\n\nThe OpenAI API is powered by a diverse set of models with different capabilities and\nprice points. You can also make customizations to our models for your specific use\n\ncase with fine-tuning.\n\nMODEL\n\nDE S CRIPTION\n\nGPT-4 and GPT-4 Turbo A set of models that improve on GPT-3.5 and can\n\nunderstand as well as generate natural language or code\n\nGPT-3.5 Turbo\n\nA set of models that improve on GPT-3.5 and can\n\nunderstand as well as generate natural language or code\n\nDALL\u00b7E\n\nA model that can generate and edit images given a natural\n\nlanguage prompt\n\nTTS\n\nA set of models that can convert text into natural sounding\n\nspoken audio\n\nWhisper\n\nA model that can convert audio into text\n\nEmbeddings\n\nA set of models that can convert text into a numerical form\n\nModeration\n\nA fine-tuned model that can detect whether text may be\n\nsensitive or unsafe\n\nGPT base\n\nDeprecated\n\nA set of models without instruction following that can\nunderstand as well as generate natural language or code\n\nA full list of models that have been deprecated along with\nthe suggested replacement\n\nWe have also published open source models including Point-E, Whisper, Jukebox, and\nCLIP.\n\nContinuous model upgrades\n\nhttps://platform.openai.com/docs/models/overview\n\n1/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\ngpt-3.5-turbo ,  gpt-4 , and  gpt-4-turbo-preview  point to the latest model\nversion. You can verify this by looking at the response object after sending a request.\nThe response will include the specific model version used (e.g.  gpt-3.5-turbo-\n0613 ).\n\nWe also offer static model versions that developers can continue using for at least\nthree months after an updated model has been introduced. With the new cadence of\nmodel updates, we are also giving people the ability to contribute evals to help us\n\nimprove the model for different use cases. If you are interested, check out the OpenAI\nEvals repository.\n\nLearn more about model deprecation on our deprecation page.\n\nGPT-4 and GPT-4 Turbo\n\nGPT-4 is a large multimodal model (accepting text or image inputs and outputting text)\nthat can solve difficult problems with greater accuracy than any of our previous\n\nmodels, thanks to its broader general knowledge and advanced reasoning capabilities.\n\nGPT-4 is available in the OpenAI API to paying customers. Like  gpt-3.5-turbo , GPT-\n\n4 is optimized for chat but works well for traditional completions tasks using the Chat\nCompletions API. Learn how to use GPT-4 in our text generation guide.\n\nMODEL\n\nDE S CRIPTION\n\nCONTEXT\nWIND OW\n\nTRAINING\nDATA\n\ngpt-4-0125-preview\n\nNew  GPT-4 Turbo\n\n128,000\n\nUp to\n\nDec\n\n2023\n\nThe latest GPT-4 model\n\ntokens\n\nintended to reduce cases of\n\n\u201claziness\u201d where the model\ndoesn\u2019t complete a task.\nReturns a maximum of\n\n4,096 output tokens.\nLearn more.\n\ngpt-4-turbo-preview\n\nCurrently points to gpt-4-\n\n0125-preview.\n\ngpt-4-1106-preview\n\nGPT-4 Turbo model\nfeaturing improved\ninstruction following, JSON\n\nmode, reproducible outputs,\nparallel function calling, and\nmore. Returns a maximum\nof 4,096 output tokens. This\n\n128,000\ntokens\n\nUp to\nDec\n2023\n\n128,000\ntokens\n\nUp to\nApr 2023\n\nhttps://platform.openai.com/docs/models/overview\n\n2/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nMODEL\n\nDE S CRIPTION\n\nis a preview model.\nLearn more.\n\nCONTEXT\nWIND OW\n\nTRAINING\nDATA\n\ngpt-4-vision-preview\n\nGPT-4 with the ability to\nunderstand images, in\n\n128,000\ntokens\n\nUp to\nApr 2023\n\naddition to all other GPT-4\nTurbo capabilities. Currently\npoints to gpt-4-1106-\n\nvision-preview.\n\ngpt-4-1106-vision-preview GPT-4 with the ability to\n\nunderstand images, in\naddition to all other GPT-4\n\nTurbo capabilities. Returns a\nmaximum of 4,096 output\n\ntokens. This is a preview\n\nmodel version. Learn more.\n\n128,000\ntokens\n\nUp to\nApr 2023\n\ngpt-4\n\ngpt-4-0613\n\nCurrently points to gpt-4-\n\n8,192\n\nUp to\n\n0613. See\n\ntokens\n\nSep 2021\n\ncontinuous model upgrades.\n\nSnapshot of gpt-4 from\n\nJune 13th 2023 with\n\nimproved function calling\n\nsupport.\n\n8,192\ntokens\n\nUp to\nSep 2021\n\ngpt-4-32k\n\nCurrently points to gpt-4-\n\ngpt-4-32k-0613\n\n32k-0613. See\n\ncontinuous model upgrades.\nThis model was never rolled\nout widely in favor of GPT-4\n\nTurbo.\n\nSnapshot of gpt-4-32k\n\nfrom June 13th 2023 with\nimproved function calling\nsupport. This model was\nnever rolled out widely in\n\nfavor of GPT-4 Turbo.\n\n32,768\n\ntokens\n\nUp to\n\nSep 2021\n\n32,768\n\ntokens\n\nUp to\n\nSep 2021\n\nFor many basic tasks, the difference between GPT-4 and GPT-3.5 models is not\nsignificant. However, in more complex reasoning situations, GPT-4 is much more\ncapable than any of our previous models.\n\nhttps://platform.openai.com/docs/models/overview\n\n3/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nMultilingual capabilities\n\nGPT-4 outperforms both previous large language models and as of 2023, most state-\nof-the-art systems (which often have benchmark-specific training or hand-\nengineering). On the MMLU benchmark, an English-language suite of multiple-choice\nquestions covering 57 subjects, GPT-4 not only outperforms existing models by a\nconsiderable margin in English, but also demonstrates strong performance in other\nlanguages.\n\nGPT-3.5 Turbo\n\nGPT-3.5 Turbo models can understand and generate natural language or code and\nhave been optimized for chat using the Chat Completions API but work well for non-\nchat tasks as well.\n\nCONTEXT\nWIND OW\n\nTRAINING\nDATA\n\n16,385\n\ntokens\n\nUp to Sep\n\n2021\n\nMODEL\n\nDE S CRIPTION\n\ngpt-3.5-turbo-0125\n\nNew  Updated GPT 3.5 Turbo\n\nThe latest GPT-3.5 Turbo\nmodel with higher accuracy at\n\nresponding in requested\n\nformats and a fix for a bug\n\nwhich caused a text encoding\nissue for non-English\n\nlanguage function calls.\n\nReturns a maximum of 4,096\n\noutput tokens. Learn more.\n\ngpt-3.5-turbo\n\nCurrently points to gpt-3.5-\n\n4,096\n\nUp to Sep\n\nturbo-0613. The gpt-3.5-\n\ntokens\n\n2021\n\nturbo model alias will be\n\nautomatically upgraded from\ngpt-3.5-turbo-0613 to\n\ngpt-3.5-turbo-0125 on\n\nFebruary 16th.\n\ngpt-3.5-turbo-1106\n\nGPT-3.5 Turbo model with\nimproved instruction\n\n16,385\ntokens\n\nUp to Sep\n2021\n\nfollowing, JSON mode,\nreproducible outputs, parallel\nfunction calling, and more.\nReturns a maximum of 4,096\n\noutput tokens. Learn more.\n\nhttps://platform.openai.com/docs/models/overview\n\n4/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nMODEL\n\nDE S CRIPTION\n\ngpt-3.5-turbo-instruct Similar capabilities as GPT-3\nera models. Compatible with\nlegacy Completions endpoint\nand not Chat Completions.\n\nCONTEXT\nWIND OW\n\nTRAINING\nDATA\n\n4,096\ntokens\n\nUp to Sep\n2021\n\ngpt-3.5-turbo-16k\n\nLegacy  Currently points to\ngpt-3.5-turbo-16k-0613.\n\n16,385\ntokens\n\nUp to Sep\n2021\n\ngpt-3.5-turbo-0613\n\nLegacy  Snapshot of gpt-3.5-\n\nturbo from June 13th 2023.\n\nWill be deprecated on June 13,\n2024.\n\n4,096\ntokens\n\nUp to Sep\n2021\n\ngpt-3.5-turbo-16k-0613\n\nLegacy  Snapshot of gpt-3.5-\n\n16,385\n\nUp to Sep\n\n16k-turbo from June 13th\n\ntokens\n\n2021\n\n2023. Will be deprecated on\n\nJune 13, 2024.\n\nDALL\u00b7E\n\nDALL\u00b7E is a AI system that can create realistic images and art from a description in\n\nnatural language. DALL\u00b7E 3 currently supports the ability, given a prompt, to create a\n\nnew image with a specific size. DALL\u00b7E 2 also support the ability to edit an existing\n\nimage, or create variations of a user provided image.\n\nDALL\u00b7E 3 is available through our Images API along with DALL\u00b7E 2. You can try DALL\u00b7E 3\n\nthrough ChatGPT Plus.\n\nMODEL\n\nDE S CRIPTION\n\ndall-e-3\n\nNew  DALL\u00b7E 3\n\nThe latest DALL\u00b7E model released in Nov 2023. Learn more.\n\ndall-e-2 The previous DALL\u00b7E model released in Nov 2022. The 2nd iteration of\nDALL\u00b7E with more realistic, accurate, and 4x greater resolution images\nthan the original model.\n\nTTS\n\nTTS is an AI model that converts text to natural sounding spoken text. We offer two\ndifferent model variates,  tts-1  is optimized for real time text to speech use cases\nand  tts-1-hd  is optimized for quality. These models can be used with the Speech\n\nendpoint in the Audio API.\n\nhttps://platform.openai.com/docs/models/overview\n\n5/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nMODEL\n\nDE S CRIPTION\n\ntts-1\n\nNew  Text-to-speech 1\nThe latest text to speech model, optimized for speed.\n\ntts-1-hd\n\nNew  Text-to-speech 1 HD\nThe latest text to speech model, optimized for quality.\n\nWhisper\n\nWhisper is a general-purpose speech recognition model. It is trained on a large dataset\nof diverse audio and is also a multi-task model that can perform multilingual speech\nrecognition as well as speech translation and language identification. The Whisper v2-\n\nlarge model is currently available through our API with the  whisper-1  model name.\n\nCurrently, there is no difference between the open source version of Whisper and the\n\nversion available through our API. However, through our API, we offer an optimized\ninference process which makes running Whisper through our API much faster than\n\ndoing it through other means. For more technical details on Whisper, you can read the\n\npaper.\n\nEmbeddings\n\nEmbeddings are a numerical representation of text that can be used to measure the\n\nrelatedness between two pieces of text. Embeddings are useful for search, clustering,\n\nrecommendations, anomaly detection, and classification tasks. You can read more\nabout our latest embedding models in the announcement blog post.\n\nMODEL\n\nDE S CRIPTION\n\ntext-embedding-\n3-large\n\nNew  Embedding V3 large\nMost capable embedding model for both\n\nenglish and non-english tasks\n\ntext-embedding-\n\nNew  Embedding V3 small\n\n3-small\n\nIncreased performance over 2nd generation ada\nembedding model\n\ntext-embedding-\nada-002\n\nMost capable 2nd generation embedding\nmodel, replacing 16 first generation models\n\nOUTP UT\nDIMENSION\n\n3,072\n\n1,536\n\n1,536\n\nModeration\n\nhttps://platform.openai.com/docs/models/overview\n\n6/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nThe Moderation models are designed to check whether content complies with\nOpenAI's usage policies. The models provide classification capabilities that look for\ncontent in the following categories: hate, hate/threatening, self-harm, sexual,\nsexual/minors, violence, and violence/graphic. You can find out more in our moderation\n\nguide.\n\nModeration models take in an arbitrary sized input that is automatically broken up into\nchunks of 4,096 tokens. In cases where the input is more than 32,768 tokens,\n\ntruncation is used which in a rare condition may omit a small number of tokens from\nthe moderation check.\n\nThe final results from each request to the moderation endpoint shows the maximum\n\nvalue on a per category basis. For example, if one chunk of 4K tokens had a category\nscore of 0.9901 and the other had a score of 0.1901, the results would show 0.9901 in the\nAPI response since it is higher.\n\nMODEL\n\nDE S CRIPTION\n\nMAX\nTOKENS\n\ntext-moderation-latest Currently points to text-moderation-\n\n32,768\n\n007.\n\ntext-moderation-stable Currently points to text-moderation-\n\n32,768\n\n007.\n\ntext-moderation-007\n\nMost capable moderation model across\nall categories.\n\n32,768\n\nGPT base\n\nGPT base models can understand and generate natural language or code but are not\ntrained with instruction following. These models are made to be replacements for our\n\noriginal GPT-3 base models and use the legacy Completions API. Most customers\n\nshould use GPT-3.5 or GPT-4.\n\nMODEL\n\nDE S CRIPTION\n\nbabbage-002 Replacement for the GPT-3 ada and\n\nbabbage base models.\n\ndavinci-002 Replacement for the GPT-3 curie and\n\ndavinci base models.\n\nMAX\nTOKENS\n\nTRAINING\nDATA\n\n16,384\ntokens\n\n16,384\ntokens\n\nUp to Sep\n2021\n\nUp to Sep\n2021\n\nHow we use your data\n\nhttps://platform.openai.com/docs/models/overview\n\n7/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nYour data is your data.\n\nAs of March 1, 2023, data sent to the OpenAI API will not be used to train or improve\n\nOpenAI models (unless you explicitly opt in). One advantage to opting in is that the\nmodels may get better at your use case over time.\n\nTo help identify abuse, API data may be retained for up to 30 days, after which it will be\n\ndeleted (unless otherwise required by law). For trusted customers with sensitive\napplications, zero data retention may be available. With zero data retention, request\nand response bodies are not persisted to any logging mechanism and exist only in\nmemory in order to serve the request.\n\nNote that this data policy does not apply to OpenAI's non-API consumer services like\nChatGPT or DALL\u00b7E Labs.\n\nDefault usage policies by endpoint\n\nENDP OINT\n\nDATA USED\nFOR TRAINING\n\nDEFAULT\nRETENTION\n\nELIGIBLE FOR\nZERO RETENTION\n\n/v1/chat/completions*\n\nNo\n\n30 days\n\nYes, except\n\nimage inputs*\n\n/v1/files\n\n/v1/assistants\n\n/v1/threads\n\n/v1/threads/messages\n\n/v1/threads/runs\n\n/v1/threads/runs/steps\n\n/v1/images/generations\n\n/v1/images/edits\n\n/v1/images/variations\n\n/v1/embeddings\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\n/v1/audio/transcriptions No\n\nUntil deleted by\n\nNo\n\ncustomer\n\nUntil deleted by\n\nNo\n\ncustomer\n\n60 days *\n\n60 days *\n\n60 days *\n\n60 days *\n\n30 days\n\n30 days\n\n30 days\n\n30 days\n\nZero data\nretention\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nYes\n\n-\n\nhttps://platform.openai.com/docs/models/overview\n\n8/10\n\n\f26/02/2024, 17:58\n\nModels - OpenAI API\n\nENDP OINT\n\nDATA USED\nFOR TRAINING\n\nDEFAULT\nRETENTION\n\nELIGIBLE FOR\nZERO RETENTION\n\n/v1/audio/translations\n\nNo\n\n/v1/audio/speech\n\n/v1/fine_tuning/jobs\n\n/v1/moderations\n\n/v1/completions\n\nNo\n\nNo\n\nNo\n\nNo\n\nZero data\nretention\n\n30 days\n\nUntil deleted by\ncustomer\n\nZero data\nretention\n\n-\n\nNo\n\nNo\n\n-\n\n30 days\n\nYes\n\n* Image inputs via the  gpt-4-vision-preview  model are not eligible for zero\nretention.\n\n* For the Assistants API, we are still evaluating the default retention period during the\n\nBeta. We expect that the default retention period will be stable after the end of the\n\nBeta.\n\nFor details, see our API data usage policies. To learn more about zero retention, get in\n\ntouch with our sales team.\n\nModel endpoint compatibility\n\nENDP OINT\n\nL ATE ST MODEL S\n\n/v1/assistants\n\nAll models except gpt-3.5-turbo-0301\n\nsupported. The retrieval tool requires gpt-4-\n\nturbo-preview (and subsequent dated model\n\nreleases) or gpt-3.5-turbo-1106 (and\n\nsubsequent versions).\n\n/v1/audio/transcriptions whisper-1\n\n/v1/audio/translations\n\nwhisper-1\n\n/v1/audio/speech\n\ntts-1, tts-1-hd\n\n/v1/chat/completions\n\ngpt-4 and dated model releases, gpt-4-turbo-\n\npreview and dated model releases, gpt-4-\n\nvision-preview, gpt-4-32k and dated model\n\nreleases, gpt-3.5-turbo and dated model\n\nhttps://platform.openai.com/docs/models/overview\n\n9/10\n\n\f26/02/2024, 17:58\n\nENDP OINT\n\nModels - OpenAI API\n\nL ATE ST MODEL S\n\nreleases, gpt-3.5-turbo-16k and dated model\n\nreleases, fine-tuned versions of gpt-3.5-turbo\n\n/v1/completions (Legacy) gpt-3.5-turbo-instruct, babbage-002,\n\ndavinci-002\n\n/v1/embeddings\n\ntext-embedding-3-small, text-embedding-\n\n3-large, text-embedding-ada-002\n\n/v1/fine_tuning/jobs\n\ngpt-3.5-turbo, babbage-002, davinci-002\n\n/v1/moderations\n\ntext-moderation-stable, text-\n\nhttps://platform.openai.com/docs/models/overview\n\n10/10\n\n\f", "pages_description": ["**GPT-4 and GPT-4 Turbo**\n\nGPT-4 is a versatile multimodal model capable of processing both text and image inputs to generate text outputs. It is designed to tackle complex problems with enhanced accuracy due to its extensive general knowledge and advanced reasoning skills. This model is accessible to paying customers via the OpenAI API and is particularly optimized for chat applications, although it can also handle traditional completion tasks using the Chat Completions API.\n\n**Model Versions:**\n\n1. **gpt-4-0125-preview**\n   - **Description:** This is the latest version of GPT-4 Turbo, aimed at reducing instances where the model fails to complete tasks, known as \"laziness.\" It can return up to 4,096 output tokens.\n   - **Context Window:** 128,000 tokens\n   - **Training Data:** Up to December 2023\n\n2. **gpt-4-turbo-preview**\n   - **Description:** This version currently points to the gpt-4-0125-preview model.\n   - **Context Window:** 128,000 tokens\n   - **Training Data:** Up to December 2023\n\n3. **gpt-4-1106-preview**\n   - **Description:** This version of GPT-4 Turbo includes enhancements such as improved instruction following, JSON mode, reproducible outputs, and parallel function calling. It also supports up to 4,096 output tokens.\n   - **Context Window:** 128,000 tokens\n   - **Training Data:** Up to April 2023\n\nThese models are part of OpenAI's efforts to provide developers with reliable and up-to-date tools for various applications, with a focus on improving performance and user experience.", "**Models - OpenAI API Overview**\n\nThis document provides an overview of various GPT-4 models, highlighting their capabilities, context windows, and training data timelines.\n\n1. **gpt-4-vision-preview**\n   - **Description**: This model is a version of GPT-4 with enhanced abilities to understand images, alongside all other GPT-4 Turbo capabilities. It currently points to the `gpt-4-1106-vision-preview`.\n   - **Context Window**: 128,000 tokens\n   - **Training Data**: Up to April 2023\n\n2. **gpt-4-1106-vision-preview**\n   - **Description**: Similar to the `gpt-4-vision-preview`, this model can understand images and includes all GPT-4 Turbo capabilities. It can return a maximum of 4,096 output tokens and is a preview model version.\n   - **Context Window**: 128,000 tokens\n   - **Training Data**: Up to April 2023\n\n3. **gpt-4**\n   - **Description**: This model currently points to `gpt-4-0613` and includes continuous model upgrades.\n   - **Context Window**: 8,192 tokens\n   - **Training Data**: Up to September 2021\n\n4. **gpt-4-0613**\n   - **Description**: A snapshot of GPT-4 from June 13th, 2023, featuring improved function calling support.\n   - **Context Window**: 8,192 tokens\n   - **Training Data**: Up to September 2021\n\n5. **gpt-4-32k**\n   - **Description**: This model points to `gpt-4-32k-0613` and includes continuous model upgrades. It was not widely rolled out, favoring GPT-4 Turbo instead.\n   - **Context Window**: 32,768 tokens\n   - **Training Data**: Up to September 2021\n\n6. **gpt-4-32k-0613**\n   - **Description**: A snapshot of `gpt-4-32k` from June 13th, 2023, with improved function calling support. Like its predecessor, it was not widely adopted in favor of GPT-4 Turbo.\n   - **Context Window**: 32,768 tokens\n   - **Training", "**Multilingual Capabilities and GPT-3.5 Turbo**\n\n**Multilingual Capabilities**\n\nGPT-4 surpasses previous large language models and, as of 2023, most state-of-the-art systems. It excels in the MMLU benchmark, which involves English-language multiple-choice questions across 57 subjects. GPT-4 not only outperforms existing models in English but also shows strong performance in other languages.\n\n**GPT-3.5 Turbo**\n\nGPT-3.5 Turbo models are designed to understand and generate natural language or code. They are optimized for chat using the Chat Completions API but are also effective for non-chat tasks.\n\n**Model Descriptions:**\n\n1. **gpt-3.5-turbo-0125**\n   - **Description:** This is the updated GPT-3.5 Turbo model with improved accuracy in responding to requested formats and a fix for a text encoding issue in non-English language function calls. It returns a maximum of 4,096 output tokens.\n   - **Context Window:** 16,385 tokens\n   - **Training Data:** Up to September 2021\n\n2. **gpt-3.5-turbo**\n   - **Description:** Currently points to gpt-3.5-turbo-0613. The alias will automatically upgrade to gpt-3.5-turbo-0125 on February 16th.\n   - **Context Window:** 4,096 tokens\n   - **Training Data:** Up to September 2021\n\n3. **gpt-3.5-turbo-1106**\n   - **Description:** Features improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. It returns a maximum of 4,096 output tokens.\n   - **Context Window:** 16,385 tokens\n   - **Training Data:** Up to September 2021", "**Models - OpenAI API**\n\n**GPT-3.5 Models:**\n\n1. **gpt-3.5-turbo-instruct**\n   - **Description:** Similar capabilities to GPT-3 era models. Compatible with legacy Completions endpoint, not Chat Completions.\n   - **Context Window:** 4,096 tokens\n   - **Training Data:** Up to September 2021\n\n2. **gpt-3.5-turbo-16k**\n   - **Description:** Legacy model pointing to gpt-3.5-turbo-16k-0613.\n   - **Context Window:** 16,385 tokens\n   - **Training Data:** Up to September 2021\n\n3. **gpt-3.5-turbo-0613**\n   - **Description:** Legacy snapshot of gpt-3.5-turbo from June 13, 2023. Will be deprecated on June 13, 2024.\n   - **Context Window:** 4,096 tokens\n   - **Training Data:** Up to September 2021\n\n4. **gpt-3.5-turbo-16k-0613**\n   - **Description:** Legacy snapshot of gpt-3.5-16k-turbo from June 13, 2023. Will be deprecated on June 13, 2024.\n   - **Context Window:** 16,385 tokens\n   - **Training Data:** Up to September 2021\n\n**DALL-E:**\n\n- **Overview:** DALL-E is an AI system that creates realistic images and art from natural language descriptions. DALL-E 3 supports creating new images with specific sizes and editing existing images or creating variations.\n- **Availability:** DALL-E 3 is available through the Images API and ChatGPT Plus.\n\n1. **dall-e-3**\n   - **Description:** The latest DALL-E model released in November 2023.\n\n2. **dall-e-2**\n   - **Description:** Released in November 2022, this model offers more realistic, accurate, and higher resolution images than the original.\n\n**TTS (Text-to-Speech):**\n\n- **Overview:** TTS converts text to natural-sounding spoken text. There are two model variants:\n  - **tts-1:** Optimized for real-time text-to-speech use cases.\n  - **tts-1-hd:** Optimized", "Text-to-Speech and Embeddings Overview\n\n**Text-to-Speech Models:**\n\n1. **tts-1**: This is a new text-to-speech model optimized for speed, providing efficient conversion of text into speech.\n\n2. **tts-1-hd**: This model is also new and focuses on optimizing the quality of the text-to-speech output.\n\n**Whisper:**\n\nWhisper is a versatile speech recognition model capable of handling diverse audio inputs. It supports multilingual speech recognition, speech translation, and language identification. The Whisper v2-large model is accessible via the API under the name `whisper-1`. While the open-source version and the API version are similar, the API offers an optimized inference process for faster performance. More technical details can be found in the associated paper.\n\n**Embeddings:**\n\nEmbeddings are numerical representations of text used to measure the relatedness between text pieces. They are crucial for tasks like search, clustering, recommendations, anomaly detection, and classification.\n\n- **text-embedding-3-large**: This is the most capable embedding model for both English and non-English tasks, with an output dimension of 3,072.\n\n- **text-embedding-3-small**: Offers improved performance over the second-generation ada embedding model, with an output dimension of 1,536.\n\n- **text-embedding-ada-002**: This is the most capable second-generation embedding model, replacing 16 first-generation models, also with an output dimension of 1,536.\n\nFor more information on the latest embedding models, you can refer to the announcement blog post.", "**Moderation Models and GPT Base**\n\n**Moderation Models**\n\nThe moderation models are designed to ensure content compliance with OpenAI's usage policies. They classify content into categories such as hate, hate/threatening, self-harm, sexual, sexual/minors, violence, and violence/graphic. These models process inputs by breaking them into chunks of 4,096 tokens. If the input exceeds 32,768 tokens, truncation may occur, potentially omitting some tokens. The moderation endpoint provides the maximum score per category from the input chunks.\n\n- **text-moderation-latest**: Points to text-moderation-007 with a maximum of 32,768 tokens.\n- **text-moderation-stable**: Also points to text-moderation-007 with the same token limit.\n- **text-moderation-007**: The most capable model across all categories, with a 32,768 token limit.\n\n**GPT Base Models**\n\nGPT base models are capable of understanding and generating natural language or code but do not follow instructions. They replace the original GPT-3 base models and use the legacy Completions API. Most users are advised to use GPT-3.5 or GPT-4.\n\n- **babbage-002**: Replaces the GPT-3 ada and babbage models, with a maximum of 16,384 tokens and training data up to September 2021.\n- **davinci-002**: Replaces the GPT-3 curie and davinci models, also with a 16,384 token limit and training data up to September 2021.", "Your Data is Your Data\n\nAs of March 1, 2023, data sent to the OpenAI API is not used to train or improve OpenAI models unless you explicitly opt in. Opting in can help models improve at your specific use case over time.\n\nTo prevent abuse, API data may be retained for up to 30 days before deletion, unless law requires otherwise. Trusted customers with sensitive applications may have zero data retention, meaning request and response bodies are not logged and exist only in memory to serve the request.\n\nThis data policy does not apply to OpenAI's non-API consumer services like ChatGPT or DALL-E Labs.\n\n**Default Usage Policies by Endpoint**\n\n- **/v1/chat/completions**: Data is not used for training. Default retention is 30 days. Eligible for zero retention, except for image inputs.\n- **/v1/files**: Data is not used for training. Retained until deleted by the customer. Not eligible for zero retention.\n- **/v1/assistants**: Data is not used for training. Retained until deleted by the customer. Not eligible for zero retention.\n- **/v1/threads**: Data is not used for training. Retained for 60 days. Not eligible for zero retention.\n- **/v1/threads/messages**: Data is not used for training. Retained for 60 days. Not eligible for zero retention.\n- **/v1/threads/runs**: Data is not used for training. Retained for 60 days. Not eligible for zero retention.\n- **/v1/threads/runs/steps**: Data is not used for training. Retained for 60 days. Not eligible for zero retention.\n- **/v1/images/generations**: Data is not used for training. Retained for 30 days. Not eligible for zero retention.\n- **/v1/images/edits**: Data is not used for training. Retained for 30 days. Not eligible for zero retention.\n- **/v1/images/variations**: Data is not used for training. Retained for 30 days. Not eligible for zero retention.\n- **/v1/embeddings**: Data is not used for training. Retained for 30 days. Eligible for zero retention.\n- **/v1/audio/transcriptions**: Data is not used for training. Zero data retention.", "**Model Endpoint Compatibility and Data Retention**\n\n**Data Retention Details:**\n\n- **/v1/audio/translations**: No data used for training, zero data retention.\n- **/v1/audio/speech**: No data used for training, 30-day retention, not eligible for zero retention.\n- **/v1/fine_tuning/jobs**: No data used for training, data retained until deleted by the customer, not eligible for zero retention.\n- **/v1/moderations**: No data used for training, zero data retention.\n- **/v1/completions**: No data used for training, 30-day retention, eligible for zero retention.\n\n*Note: Image inputs via the gpt-4-vision-preview model are not eligible for zero retention. The default retention period for the Assistants API is still under evaluation during the Beta phase.*\n\n**Model Endpoint Compatibility:**\n\n- **/v1/assistants**: Supports all models except gpt-3.5-turbo-0301. The retrieval tool requires gpt-4-turbo-preview or gpt-3.5-turbo-1106.\n- **/v1/audio/transcriptions**: Compatible with whisper-1.\n- **/v1/audio/translations**: Compatible with whisper-1.\n- **/v1/audio/speech**: Compatible with tts-1, tts-1-hd.\n- **/v1/chat/completions**: Compatible with gpt-4, gpt-4-turbo-preview, gpt-4-vision-preview, gpt-4-32k, gpt-3.5-turbo, and their dated model releases.\n\nFor more details, refer to the API data usage policies or contact the sales team for information on zero retention.", "LATEST MODELS\n\nThis document outlines the latest models available for different API endpoints in the OpenAI platform:\n\n1. **Releases**: \n   - The latest models include `gpt-3.5-turbo-16k` and dated model releases, along with fine-tuned versions of `gpt-3.5-turbo`.\n\n2. **/v1/completions (Legacy)**:\n   - Models available: `gpt-3.5-turbo-instruct`, `babbage-002`, `davinci-002`.\n\n3. **/v1/embeddings**:\n   - Models available: `text-embedding-3-small`, `text-embedding-3-large`, `text-embedding-ada-002`.\n\n4. **/v1/fine_tuning/jobs**:\n   - Models available: `gpt-3.5-turbo`, `babbage-002`, `davinci-002`.\n\n5. **/v1/moderations**:\n   - Models available: `text-moderation-stable`.\n\nThese models are designed for various tasks such as generating text completions, creating embeddings for text, fine-tuning, and moderating content. Each model is optimized for specific use cases, providing flexibility and efficiency for developers using the OpenAI API."]}, {"filename": "evals-decks.pdf", "text": "Evaluation\nTechnique\n\nFebruary 2024\n\n\fOverview\n\nEvaluation is the process of validating \nand testing the outputs that your LLM \napplications are producing. Having \nstrong evaluations (\u201cevals\u201d) will mean a \nmore stable, reliable application which is \nresilient to code and model changes.\n\nExample use cases\n\n- Quantify a solution\u2019s reliability\n- Monitor application performance in \n\nproduction\nTest for regressions \n\n-\n\nWhat we\u2019ll cover\n\n\u25cf What are evals\n\n\u25cf Technical patterns\n\n\u25cf Example framework\n\n\u25cf Best practices\n\n\u25cf Resources\n\n3\n\n\fWhat are evals\nExample\n\nAn evaluation contains a question and a correct answer. We call this the ground truth.\n\nQuestion\n\nWhat is the population \nof Canada?\n\nThought: I don\u2019t know. I \nshould use a tool\nAction: Search\nAction Input: What is the \npopulation of Canada?\n\nLLM\n\nSearch\n\nThere are 39,566,248 people \nin Canada as of 2023.\n\nThe current population of \nCanada is 39,566,248 as of \nTuesday, May 23, 2023\u2026.\n\nActual result\n\n4\n\n\fWhat are evals\nExample\n\nOur ground truth matches the predicted answer, so the evaluation passes!\n\nEvaluation\n\nQuestion\n\nGround Truth\n\nPredicted Answer\n\nWhat is the population \nof Canada?\n\nThe population of Canada in \n2023 is 39,566,248 people.\n\nThere are 39,566,248 people \nin Canada as of 2023.\n\n5\n\n\fTechnical patterns\n\nMetric-based evaluations\n\nComponent evaluations\n\nSubjective evaluations\n\n\u25cf\n\n\u25cf\n\nComparison metrics like \nBLEU, ROUGE\n\nGives a score to \ufb01lter and \nrank results\n\n\u25cf\n\n\u25cf\n\nCompares ground \ntruth to prediction\n\nGives Pass/Fail\n\n\u25cf\n\n\u25cf\n\nUses a scorecard to \nevaluate subjectively\n\nScorecard may also \nhave a Pass/Fail\n\n6\n\n\fTechnical patterns\nMetric-based evaluations\n\nROUGE is a common metric for evaluating machine summarizations of text\n\nROUGE\n\nMetric for evaluating \nsummarization tasks\n\nOriginal\n\nOpenAI's mission is to ensure that \narti\ufb01cial general intelligence (AGI) \nbene\ufb01ts all of humanity. OpenAI \nwill build safe and bene\ufb01cial AGI \ndirectly, but will also consider its \nmission ful\ufb01lled if its work aids \nothers to achieve this outcome. \nOpenAI follows several key \nprinciples for this purpose. First, \nbroadly distributed bene\ufb01ts - any \nin\ufb02uence over AGI's deployment \nwill be used for the bene\ufb01t of all, \nand to avoid harmful uses or undue \nconcentration of power\u2026\n\nMachine \nSummary\n\nOpenAI aims to ensure AGI is \nfor everyone's use, totally \navoiding harmful stuff or big \npower concentration. \nCommitted to researching \nAGI's safe side, promoting \nthese studies in AI folks. \nOpenAI wants to be top in AI \nthings and works with \nworldwide research, policy \ngroups to \ufb01gure AGI's stuff.\n\nROUGE \nScore\n\n0.51162\n\n7\n\n\fTechnical patterns\nMetric-based evaluations\n\nBLEU score is another standard metric, this time focusing on machine translation tasks\n\nBLEU\n\nOriginal text\n\nReference\nTranslation\n\nPredicted \nTranslation\n\nMetric for \nevaluating \ntranslation tasks\n\nY gwir oedd \ndoedden nhw \nddim yn dweud \ncelwyddau wedi'r \ncwbl.\n\nThe truth was \nthey were not \ntelling lies after \nall.\n\nThe truth was \nthey weren't \ntelling lies after \nall.\n\nBLEU \nScore\n\n0.39938\n\n8\n\n\fTechnical patterns\nMetric-based evaluations\n\nWhat they\u2019re good for\n\nWhat to be aware of\n\n\u25cf\n\n\u25cf\n\nA good starting point for evaluating a \n\n\u25cf Not tuned to your speci\ufb01c context\n\nfresh solution\n\nUseful yardstick for automated testing \n\nof whether a change has triggered a \n\nmajor performance shift\n\n\u25cf Most customers require more \n\nsophisticated evaluations to go to \n\nproduction\n\n\u25cf Cheap and fast\n\n9\n\n\fTechnical patterns\nComponent evaluations\n\nComponent evaluations (or \u201cunit tests\u201d) cover a single input/output of the application. They check \nwhether each component works in isolation, comparing the input to a ground truth ideal result\n\nIs this the \ncorrect action?\n\nExact match \ncomparison\n\nDoes this answer \nuse the context?\n\nExtract numbers \nfrom each and \ncompare\n\nWhat is the population \nof Canada?\n\nThought: I don\u2019t know. I \nshould use a tool\nAction: Search\nAction Input: What is the \npopulation of Canada?\n\nAgent\n\nSearch\n\nThere are 39,566,248 people \nin Canada as of 2023.\n\nThe current population of \nCanada is 39,566,248 as of \nTuesday, May 23, 2023\u2026.\n\nIs this the right \nsearch result?\n\nTag the right \nanswer and do \nan exact match \ncomparison with \nthe retrieval.\n\n10\n\n\fTechnical patterns\nSubjective evaluations\n\nBuilding up a good scorecard for automated testing bene\ufb01ts from a few rounds of detailed human \nreview so we can learn what is valuable. \n\nA policy of \u201cshow rather than tell\u201d is also advised for GPT-4, so include examples of what a 1, 3 and \n8 out of 10 look like so the model can appreciate the spread.\n\nExample \nscorecard\n\nYou are a helpful evaluation assistant who grades how well the Assistant has answered the customer\u2019s query.\n\nYou will assess each submission against these metrics, please think through these step by step:\n\n-\n\nrelevance: Grade how relevant the search content is to the question from 1 to 5 // 5 being highly relevant and 1 being \nnot relevant at all.\n\n- credibility: Grade how credible the sources provided are from 1 to 5 // 5 being an established newspaper, \n\n-\n\ngovernment agency or large company and 1 being unreferenced.\nresult: Assess whether the question is correct given only the content returned from the search and the user\u2019s \nquestion // acceptable values are \u201ccorrect\u201d or \u201cincorrect\u201d\n\nYou will output this as a JSON document: {relevance: integer, credibility: integer, result: string}\n\nUser: What is the population of Canada?\nAssistant: Canada's population was estimated at 39,858,480 on April 1, 2023 by Statistics Canada.\nEvaluation: {relevance: 5, credibility: 5, result: correct}\n\n11\n\n\fExample framework\n\nYour evaluations can be grouped up into test suites called runs and executed in a batch to test \nthe e\ufb00ectiveness of your system.\n\nEach run should have its contents logged and stored at the most granular level possible \n(\u201ctracing\u201d) so you can investigate failure reasons, make tweaks and then rerun your evals.\n\nRun ID Model\n\nScore\n\nAnnotation feedback\n\nChanges since last run\n\n1\n\n2\n\n3\n\n4\n\n5\n\ngpt-3.5-turbo 28/50\n\ngpt-4\n\n36/50\n\ngpt-3.5-turbo 34/50\n\n\u25cf 18 incorrect with correct search results\n\u25cf 4 incorrect searches\n\nN/A\n\n\u25cf 10 incorrect with correct search results\n\u25cf 4 incorrect searches\n\n\u25cf 12 incorrect with correct search results\n\u25cf 4 incorrect searches\n\nModel updated to GPT-4\n\nAdded few-shot examples\n\ngpt-3.5-turbo 42/50\n\n\u25cf 8 incorrect with correct search results\n\nAdded metadata to search\nPrompt engineering for Answer step\n\ngpt-3.5-turbo 48/50\n\n\u25cf 2 incorrect with correct search results\n\nPrompt engineering to Answer step\n\n12\n\n\fExample framework\n\nI want to return a \nT-shirt I bought on \nAmazon on March 3rd.\n\nUser\n\nRouter\n\nLLM\n\nExpected: return\nPredicted: return\nPASS\n\nReturn\nAssistant\n\nLLM\n\nComponent evals\n\nSubjective evals\n\nExpected: return_policy\nPredicted: return_policy\nPASS\n\nKnowledge \nbase\n\nQuestion: Does this response adhere to \nour guidelines\nScore: \nPoliteness: 5, Coherence: 4, Relevancy: 4\nPASS\n\nSure - because we\u2019re \nwithin 14 days of the \npurchase, I can \nprocess the return\n\nQuestion: I want to return a T-shirt I \nbought on Amazon on March 3rd.\nGround truth: Eligible for return\nPASS\n\n13\n\n\fBest practices\n\nLog everything\n\n\u25cf\n\nEvals need test cases - log everything as you develop so you can mine your logs for good eval cases\n\nCreate a feedback loop\n\n\u25cf\n\u25cf\n\nBuild evals into your application so you can quickly run them, iterate and rerun to see the impact\nEvals also provide a useful structure for few-shot or \ufb01ne-tuning examples when optimizing\n\nEmploy expert labellers who know the process\n\n\u25cf Use experts to help create your eval cases - these need to be as lifelike as possible\n\nEvaluate early and often\n\n\u25cf\n\nEvals are something you should build as soon as you have your \ufb01rst functioning prompt - you won\u2019t be \nable to optimize without this baseline, so build it early\n\n\u25cf Making evals early also forces you to engage with what a good response looks like\n\n\f", "pages_description": ["**Overview**\n\nEvaluation is the process of validating and testing the outputs that your Large Language Model (LLM) applications are producing. Strong evaluations, referred to as \"evals,\" contribute to creating a more stable and reliable application that can withstand changes in code and model updates.\n\n**Example Use Cases:**\n\n- Quantifying a solution\u2019s reliability\n- Monitoring application performance in production\n- Testing for regressions\n\n**What We\u2019ll Cover:**\n\n- What are evals\n- Technical patterns\n- Example framework\n- Best practices\n- Resources\n\nThis overview highlights the importance of evaluations in ensuring the robustness and reliability of LLM applications, providing a foundation for understanding how to implement and benefit from them effectively.", "What are evals\n\nAn evaluation, or \"eval,\" involves a question and a correct answer, referred to as the \"ground truth.\" This example illustrates the process:\n\n1. **Question**: A person asks, \"What is the population of Canada?\"\n\n2. **LLM (Language Learning Model) Response**:\n   - **Thought**: The model acknowledges it doesn't know the answer and decides to use a tool.\n   - **Action**: It chooses to perform a search.\n   - **Action Input**: The model inputs the question, \"What is the population of Canada?\" into the search tool.\n\n3. **Search Result**: The search tool provides the information, stating, \"The current population of Canada is 39,566,248 as of Tuesday, May 23, 2023.\"\n\n4. **Actual Result**: The model relays the information back, confirming, \"There are 39,566,248 people in Canada as of 2023.\"\n\nThis process demonstrates how evaluations are used to verify the accuracy of a model's response by comparing it to the ground truth.", "What are evals\n\nThis example explains the concept of evaluations, often referred to as \"evals,\" in the context of comparing predicted answers to known correct answers, or \"ground truth.\"\n\n- **Question**: The example question is \"What is the population of Canada?\"\n\n- **Ground Truth**: The correct answer provided is \"The population of Canada in 2023 is 39,566,248 people.\"\n\n- **Predicted Answer**: The predicted response is \"There are 39,566,248 people in Canada as of 2023.\"\n\nThe evaluation process involves comparing the predicted answer to the ground truth. In this case, both the ground truth and the predicted answer match, indicating that the evaluation passes successfully. This process is crucial for validating the accuracy of predictions in various applications.", "**Technical Patterns**\n\nThis content describes three types of evaluation methods used in technical assessments:\n\n1. **Metric-based Evaluations**:\n   - Utilizes comparison metrics such as BLEU and ROUGE.\n   - These metrics provide a score that helps in filtering and ranking results, offering a quantitative measure of performance.\n\n2. **Component Evaluations**:\n   - Involves comparing the ground truth to predictions.\n   - The outcome is typically a Pass/Fail result, indicating whether the component meets the expected standards.\n\n3. **Subjective Evaluations**:\n   - Employs a scorecard for subjective assessment.\n   - The scorecard can also include a Pass/Fail option, allowing for a qualitative evaluation of performance.\n\nEach method provides a different approach to evaluating technical performance, balancing between quantitative metrics and qualitative judgments.", "Technical Patterns: Metric-based Evaluations\n\nROUGE is a common metric for evaluating machine summarizations of text. It is specifically used to assess the quality of summaries by comparing them to reference summaries. The slide provides an example of how ROUGE is applied:\n\n- **ROUGE**: This is a metric for evaluating summarization tasks. It measures the overlap of n-grams, word sequences, and word pairs between the machine-generated summary and the reference summary.\n\n- **Original Text**: The original passage discusses OpenAI's mission to ensure that artificial general intelligence (AGI) benefits all of humanity. It emphasizes building safe and beneficial AGI, considering its mission fulfilled if it aids others, and following key principles to avoid harmful uses or undue concentration of power.\n\n- **Machine Summary**: The machine-generated summary simplifies the original text, stating that OpenAI aims to ensure AGI is safe for everyone's use, avoids harmful impacts, and prevents power concentration. It highlights OpenAI's commitment to researching AGI's safety and collaborating with global research and policy groups.\n\n- **ROUGE Score**: The score given is 0.51162, indicating the level of similarity between the machine summary and the original text. A higher score suggests a closer match to the reference summary.\n\nThis example illustrates how ROUGE can be used to evaluate the effectiveness of machine-generated summaries in capturing the essence of the original text.", "Technical Patterns: Metric-based Evaluations\n\nThe slide discusses the BLEU score, a standard metric used to evaluate machine translation tasks. BLEU stands for Bilingual Evaluation Understudy and is a method for assessing the quality of text that has been machine-translated from one language to another.\n\n- **BLEU**: It is a metric for evaluating translation tasks, focusing on how closely a machine-generated translation matches a reference translation.\n\n- **Original Text**: The example given is in Welsh: \"Y gwir oedd doedden nhw ddim yn dweud celwyddau wedi'r cwbl.\"\n\n- **Reference Translation**: The English translation provided is \"The truth was they were not telling lies after all.\"\n\n- **Predicted Translation**: The machine-generated translation is \"The truth was they weren't telling lies after all.\"\n\n- **BLEU Score**: The score for this translation is 0.39938, indicating the level of similarity between the predicted translation and the reference translation. A higher BLEU score suggests a closer match to the reference translation.", "Technical Patterns: Metric-based Evaluations\n\n**What they\u2019re good for:**\n\n- **Starting Point:** They provide a good starting point for evaluating a new solution.\n- **Automated Testing:** Serve as a useful measure for automated testing to determine if a change has caused a significant performance shift.\n- **Cost-Effective:** They are cheap and fast to implement.\n\n**What to be aware of:**\n\n- **Context Specificity:** These evaluations are not tailored to specific contexts.\n- **Sophistication Needs:** Most customers require more sophisticated evaluations before moving to production.", "**Technical Patterns: Component Evaluations**\n\nComponent evaluations, also known as \"unit tests,\" focus on assessing a single input/output of an application. The goal is to verify whether each component functions correctly in isolation by comparing the input to a ground truth or ideal result.\n\n**Process Overview:**\n\n1. **Input Question:** \n   - The process begins with a question: \"What is the population of Canada?\"\n\n2. **Agent's Role:**\n   - The agent receives the question and processes it. The agent's thought process is: \"I don\u2019t know. I should use a tool.\"\n   - The agent decides on an action: \"Search.\"\n   - The action input is the original question: \"What is the population of Canada?\"\n\n3. **Search Component:**\n   - The search component is tasked with finding the answer. It retrieves the information: \"The current population of Canada is 39,566,248 as of Tuesday, May 23, 2023\u2026.\"\n\n4. **Evaluation Steps:**\n   - **Correct Action Check:** Determine if the agent's decision to search was appropriate.\n   - **Exact Match Comparison:** Compare the retrieved answer with the expected result.\n   - **Contextual Relevance:** Assess if the answer uses the context correctly.\n   - **Number Extraction and Comparison:** Extract numbers from both the expected and retrieved answers and compare them for accuracy.\n\n5. **Final Output:**\n   - The final answer provided is: \"There are 39,566,248 people in Canada as of 2023.\"\n\nThis process ensures that each component of the application is functioning correctly by isolating and testing individual parts against a known standard.", "**Technical Patterns: Subjective Evaluations**\n\nBuilding an effective scorecard for automated testing is enhanced by incorporating detailed human reviews. This process helps identify what is valuable in the evaluation. The approach of \"show rather than tell\" is recommended for GPT-4, meaning that examples of scores like 1, 3, and 8 out of 10 should be provided to help the model understand the range of evaluations.\n\n**Example Scorecard**\n\nThe example scorecard outlines a method for evaluating how well an assistant answers a customer's query. The evaluation is based on three metrics:\n\n1. **Relevance**: This measures how relevant the search content is to the question, on a scale from 1 to 5, where 5 is highly relevant and 1 is not relevant at all.\n\n2. **Credibility**: This assesses the credibility of the sources, also on a scale from 1 to 5. A score of 5 indicates an established newspaper, government agency, or large company, while 1 indicates an unreferenced source.\n\n3. **Result**: This determines whether the answer is correct based on the content returned from the search and the user's question. The acceptable values are \"correct\" or \"incorrect.\"\n\nThe output is formatted as a JSON document with the structure: `{relevance: integer, credibility: integer, result: string}`.\n\n**Example Evaluation**\n\n- **User Query**: \"What is the population of Canada?\"\n- **Assistant Response**: \"Canada's population was estimated at 39,858,480 on April 1, 2023, by Statistics Canada.\"\n- **Evaluation**: `{relevance: 5, credibility: 5, result: correct}`\n\nThis example demonstrates a high relevance and credibility score, with the result being correct, indicating a well-answered query.", "**Example Framework**\n\nThis framework outlines a method for evaluating the effectiveness of a system through test suites called \"runs.\" These runs are executed in batches, and each run's contents are logged and stored at a detailed level, known as \"tracing.\" This allows for investigation into failure reasons, making necessary adjustments, and rerunning evaluations.\n\nThe table provided includes the following columns:\n\n- **Run ID**: Identifies each test run.\n- **Model**: Specifies the model used in the run.\n- **Score**: Indicates the performance score out of 50.\n- **Annotation Feedback**: Provides feedback on the run, detailing the number of incorrect results despite correct search results and the number of incorrect searches.\n- **Changes Since Last Run**: Lists any modifications made since the previous run.\n\n**Details of Each Run:**\n\n1. **Run 1**: \n   - Model: gpt-3.5-turbo\n   - Score: 28/50\n   - Feedback: 18 incorrect with correct search results, 4 incorrect searches\n   - Changes: None\n\n2. **Run 2**: \n   - Model: gpt-4\n   - Score: 36/50\n   - Feedback: 10 incorrect with correct search results, 4 incorrect searches\n   - Changes: Model updated to GPT-4\n\n3. **Run 3**: \n   - Model: gpt-3.5-turbo\n   - Score: 34/50\n   - Feedback: 12 incorrect with correct search results, 4 incorrect searches\n   - Changes: Added few-shot examples\n\n4. **Run 4**: \n   - Model: gpt-3.5-turbo\n   - Score: 42/50\n   - Feedback: 8 incorrect with correct search results\n   - Changes: Added metadata to search, prompt engineering for answer step\n\n5. **Run 5**: \n   - Model: gpt-3.5-turbo\n   - Score: 48/50\n   - Feedback: 2 incorrect with correct search results\n   - Changes: Prompt engineering to answer step\n\nThis framework helps in systematically improving the system by analyzing performance, making informed changes, and tracking progress over multiple runs.", "**Example Framework**\n\nThis diagram illustrates a framework for processing a user's request to return a T-shirt purchased on Amazon. Here's a breakdown of the process:\n\n1. **User Input**: The user expresses a desire to return a T-shirt bought on March 3rd.\n\n2. **Router**: \n   - The user's request is first handled by a component labeled \"Router,\" which uses a Large Language Model (LLM).\n   - The expected and predicted outcomes are both \"return,\" and the process passes this evaluation.\n\n3. **Return Assistant**:\n   - The request is then passed to the \"Return Assistant,\" which also utilizes an LLM.\n   - This component checks the return policy by consulting a \"Knowledge base.\"\n   - The expected and predicted outcomes are both \"return_policy,\" and this step also passes.\n\n4. **Response to User**:\n   - The system responds to the user, confirming that the return can be processed because it is within 14 days of purchase.\n\n5. **Evaluation**:\n   - The response is evaluated based on politeness, coherence, and relevancy, scoring 5, 4, and 4, respectively, and it passes the evaluation.\n\n6. **Ground Truth**:\n   - The ground truth confirms that the item is eligible for return, and this is also marked as a pass.\n\nThe framework includes both component evaluations (in red dashed lines) and subjective evaluations (in orange dashed lines) to ensure the process adheres to guidelines and provides a satisfactory user experience.", "**Best Practices**\n\n1. **Log Everything**\n   - It's crucial to log all activities during development to create effective evaluation cases. This comprehensive logging allows you to mine your logs for valuable insights and test cases.\n\n2. **Create a Feedback Loop**\n   - Integrate evaluations into your application to quickly run, iterate, and rerun them, enabling you to observe the impact of changes. Evaluations also offer a useful framework for few-shot or fine-tuning examples during optimization.\n\n3. **Employ Expert Labelers Who Know the Process**\n   - Utilize experts to develop your evaluation cases, ensuring they are as realistic as possible. This expertise helps in creating lifelike and relevant test scenarios.\n\n4. **Evaluate Early and Often**\n   - Begin building evaluations as soon as you have your first functioning prompt. Establishing a baseline early is essential for effective optimization. Early evaluations also compel you to understand what constitutes a good response, enhancing the overall quality of your application."]}, {"filename": "fine-tuning-deck.pdf", "text": "Fine-tuning\nTechnique\n\nFebruary 2024\n\n\fOverview\n\nFine-tuning involves adjusting the \nparameters of pre-trained models on a \nspeci\ufb01c dataset or task. This process \nenhances the model's ability to generate \nmore accurate and relevant responses for \nthe given context by adapting it to the \nnuances and speci\ufb01c requirements of the \ntask at hand.\n\nExample use cases\n\n- Generate output in a consistent \n\n-\n\nformat\nProcess input by following speci\ufb01c \ninstructions\n\nWhat we\u2019ll cover\n\n\u25cf When to \ufb01ne-tune\n\n\u25cf Preparing the dataset\n\n\u25cf Best practices\n\n\u25cf Hyperparameters\n\n\u25cf Fine-tuning advances\n\n\u25cf Resources\n\n3\n\n\fWhat is Fine-tuning\n\nPublic Model\n\nTraining data\n\nTraining\n\nFine-tuned \nmodel\n\nFine-tuning a model consists of training the \nmodel to follow a set of given input/output \nexamples.\n\nThis will teach the model to behave in a \ncertain way when confronted with a similar \ninput in the future.\n\nWe recommend using 50-100 examples \n\neven if the minimum is 10.\n\n4\n\n\fWhen to \ufb01ne-tune\n\nGood for  \u2705\n\nNot good for  \u274c\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\nFollowing a given format or tone for the \n\noutput\n\nProcessing the input following speci\ufb01c, \n\ncomplex instructions\n\nImproving latency\n\nReducing token usage\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\nTeaching the model new knowledge\n\u2794 Use RAG or custom models instead\n\nPerforming well at multiple, unrelated tasks\n\u2794 Do prompt-engineering or create multiple \n\nFT models instead\n\nInclude up-to-date content in responses\n\u2794 Use RAG instead\n\n5\n\n\fPreparing the dataset\n\nExample format\n\n{\n\n\"messages\": [\n\n{\n\n\"role\": \"system\",\n\"content\": \"Marv is a factual chatbot \nthat is also sarcastic.\"\n\n},\n{\n\n\"role\": \"user\",\n\"content\": \"What's the capital of \nFrance?\"\n\n},\n{\n\n\"role\": \"assistant\",\n\"content\": \"Paris, as if everyone \ndoesn't know that already.\"\n\n}\n\n]\n\n}\n\n.jsonl\n\n\u2794 Take the set of instructions and prompts that you \n\nfound worked best for the model prior to \ufb01ne-tuning. \nInclude them in every training example\n\n\u2794 If you would like to shorten the instructions or \n\nprompts, it may take more training examples to arrive \nat good results\n\nWe recommend using 50-100 examples \n\neven if the minimum is 10.\n\n6\n\n\fBest practices\n\nCurate examples carefully\n\nDatasets can be di\ufb03cult to build, start \nsmall and invest intentionally. \nOptimize for fewer high-quality \ntraining examples.\n\n\u25cf Consider \u201cprompt baking\u201d, or using a basic \nprompt to generate your initial examples\n\u25cf If your conversations are multi-turn, ensure \n\nyour examples are representative\n\n\u25cf Collect examples to target issues detected \n\nin evaluation\n\n\u25cf Consider the balance & diversity of data\n\u25cf Make sure your examples contain all the \n\ninformation needed in the response\n\nIterate on hyperparameters\n\nEstablish a baseline\n\nStart with the defaults and adjust \nbased on performance.\n\n\u25cf If the model does not appear to converge, \n\nincrease the learning rate multiplier\n\u25cf If the model does not follow the training \ndata as much as expected increase the \nnumber of epochs\n\n\u25cf If the model becomes less diverse than \n\nexpected decrease the # of epochs by 1-2\n\nAutomate your feedback \npipeline\n\nIntroduce automated evaluations to \nhighlight potential problem cases to \nclean up and use as training data.\n\nConsider the G-Eval approach of \nusing GPT-4 to perform automated \ntesting using a scorecard.\n\nOften users start with a \nzero-shot or few-shot prompt to \nbuild a baseline evaluation \nbefore graduating to \ufb01ne-tuning.\n\nOften users start with a \nzero-shot or few-shot prompt to \nbuild a baseline evaluation \nOptimize for latency and \nbefore graduating to \ufb01ne-tuning.\ntoken e\ufb03ciency\n\nWhen using GPT-4, once you \nhave a baseline evaluation and \ntraining examples consider \n\ufb01ne-tuning 3.5 to get similar \nperformance for less cost and \nlatency.\n\nExperiment with reducing or \nremoving system instructions \nwith subsequent \ufb01ne-tuned \nmodel versions.\n\n\fHyperparameters\n\nEpochs\nRefers to 1 full cycle through the training dataset\nIf you have hundreds of thousands of examples, we would recommend \nexperimenting with two epochs (or one) to avoid over\ufb01tting.\n\ndefault: auto (standard is 4)\n\nBatch size\nNumber of training examples used to train a single \nforward & backward pass\nIn general, we've found that larger batch sizes tend to work better for larger datasets\n\ndefault: ~0.2% x N* (max 256)\n\n*N = number of training examples\n\nLearning rate multiplier\nScaling factor for the original learning rate\nWe recommend experimenting with values between 0.02-0.2. We've found that \nlarger learning rates often perform better with larger batch sizes.\n\ndefault: 0.05, 0.1 or 0.2*\n\n*depends on \ufb01nal batch size\n\n8\n\n\f", "pages_description": ["**Overview**\n\nFine-tuning involves adjusting the parameters of pre-trained models on a specific dataset or task. This process enhances the model's ability to generate more accurate and relevant responses by adapting it to the nuances and specific requirements of the task at hand.\n\n**Example Use Cases:**\n- Generate output in a consistent format.\n- Process input by following specific instructions.\n\n**What We\u2019ll Cover:**\n- When to fine-tune\n- Preparing the dataset\n- Best practices\n- Hyperparameters\n- Fine-tuning advances\n- Resources", "What is Fine-tuning\n\nFine-tuning is the process of training a model to follow a set of specific input/output examples. This involves taking a pre-existing public model and using training data to adjust its parameters. The goal is to teach the model to respond in a desired way when it encounters similar inputs in the future.\n\nThe diagram illustrates this process: \n\n1. **Public Model**: The starting point, which is a general model available for use.\n2. **Training Data**: A collection of examples that the model will learn from.\n3. **Training**: The phase where the model is adjusted based on the training data.\n4. **Fine-tuned Model**: The result, which is a model tailored to specific needs.\n\nIt is recommended to use 50-100 examples for effective fine-tuning, although the minimum required is 10. This ensures the model learns adequately from the examples provided.", "**When to Fine-Tune**\n\nFine-tuning a model can be beneficial or not, depending on the specific needs and goals. Here's a breakdown:\n\n**Good for:**\n\n1. **Following a given format or tone for the output**: Fine-tuning helps the model adhere to specific styles or formats required for the output.\n\n2. **Processing the input following specific, complex instructions**: It allows the model to handle detailed and intricate instructions effectively.\n\n3. **Improving latency**: Fine-tuning can enhance the speed at which the model processes information.\n\n4. **Reducing token usage**: It can optimize the model to use fewer tokens, making it more efficient.\n\n**Not good for:**\n\n1. **Teaching the model new knowledge**: Fine-tuning is not suitable for introducing new information. Instead, using Retrieval-Augmented Generation (RAG) or custom models is recommended.\n\n2. **Performing well at multiple, unrelated tasks**: For diverse tasks, prompt-engineering or creating multiple fine-tuned models is more effective.\n\n3. **Including up-to-date content in responses**: Fine-tuning is not ideal for ensuring the latest information is included. RAG is a better alternative for this purpose.", "**Preparing the Dataset**\n\nThis slide provides guidance on preparing a dataset for training a chatbot model. It includes an example format in JSON Lines (.jsonl) and offers recommendations for effective dataset preparation.\n\n**Example Format:**\n\nThe dataset is structured as a series of messages, each with a specific role and content:\n\n- **System Message:**\n  - **Role:** \"system\"\n  - **Content:** \"Marv is a factual chatbot that is also sarcastic.\"\n\n- **User Message:**\n  - **Role:** \"user\"\n  - **Content:** \"What's the capital of France?\"\n\n- **Assistant Message:**\n  - **Role:** \"assistant\"\n  - **Content:** \"Paris, as if everyone doesn't know that already.\"\n\n**Recommendations:**\n\n- **Instructions and Prompts:**\n  - Use the set of instructions and prompts that have proven effective for the model before fine-tuning. These should be included in every training example.\n\n- **Shortening Instructions:**\n  - If you choose to shorten the instructions or prompts, be aware that more training examples may be needed to achieve good results.\n\n- **Example Quantity:**\n  - It is recommended to use 50-100 examples, even though the minimum required is 10. This helps ensure the model is well-trained and performs effectively.", "**Best Practices**\n\n1. **Curate Examples Carefully**\n   - Building datasets can be challenging, so start small and focus on high-quality examples.\n   - Use \"prompt baking\" to generate initial examples.\n   - Ensure multi-turn conversations are well-represented.\n   - Collect examples to address issues found during evaluation.\n   - Balance and diversify your data.\n   - Ensure examples contain all necessary information for responses.\n\n2. **Iterate on Hyperparameters**\n   - Begin with default settings and adjust based on performance.\n   - Increase the learning rate multiplier if the model doesn't converge.\n   - Increase the number of epochs if the model doesn't follow training data closely.\n   - Decrease the number of epochs by 1-2 if the model becomes less diverse.\n\n3. **Establish a Baseline**\n   - Start with zero-shot or few-shot prompts to create a baseline before fine-tuning.\n\n4. **Automate Your Feedback Pipeline**\n   - Use automated evaluations to identify and clean up problem cases for training data.\n   - Consider using the G-Eval approach with GPT-4 for automated testing with a scorecard.\n\n5. **Optimize for Latency and Token Efficiency**\n   - After establishing a baseline, consider fine-tuning with GPT-3.5 for similar performance at lower cost and latency.\n   - Experiment with reducing or removing system instructions in subsequent fine-tuned models.", "Hyperparameters\n\n**Epochs**\n\n- **Definition**: An epoch refers to one complete cycle through the entire training dataset.\n- **Recommendation**: If you have a large dataset with hundreds of thousands of examples, consider using fewer epochs (one or two) to prevent overfitting.\n- **Default Setting**: Auto, with a standard of 4 epochs.\n\n**Batch Size**\n\n- **Definition**: This is the number of training examples used in one forward and backward pass of the training process.\n- **Insight**: Larger batch sizes are generally more effective for larger datasets.\n- **Default Setting**: Approximately 0.2% of the total number of training examples, with a maximum of 256.\n\n**Learning Rate Multiplier**\n\n- **Definition**: This is a scaling factor applied to the original learning rate.\n- **Recommendation**: Experiment with values between 0.02 and 0.2. Larger learning rates often yield better results with larger batch sizes.\n- **Default Setting**: Options include 0.05, 0.1, or 0.2, depending on the final batch size."]}]